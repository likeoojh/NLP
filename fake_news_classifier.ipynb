{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T08:32:22.350607Z",
     "start_time": "2020-06-29T08:32:21.299514Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/fakenews_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T08:32:23.213872Z",
     "start_time": "2020-06-29T08:32:23.160937Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20795</td>\n",
       "      <td>Rapper T.I.: Trump a ’Poster Child For White S...</td>\n",
       "      <td>Rapper T. I. unloaded on black celebrities who...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20796</td>\n",
       "      <td>N.F.L. Playoffs: Schedule, Matchups and Odds -...</td>\n",
       "      <td>When the Green Bay Packers lost to the Washing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20797</td>\n",
       "      <td>Macy’s Is Said to Receive Takeover Approach by...</td>\n",
       "      <td>The Macy’s of today grew from the union of sev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20798</td>\n",
       "      <td>NATO, Russia To Hold Parallel Exercises In Bal...</td>\n",
       "      <td>NATO, Russia To Hold Parallel Exercises In Bal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20799</td>\n",
       "      <td>What Keeps the F-35 Alive</td>\n",
       "      <td>David Swanson is an author, activist, journa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20800 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
       "1      FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
       "2                      Why the Truth Might Get You Fired   \n",
       "3      15 Civilians Killed In Single US Airstrike Hav...   \n",
       "4      Iranian woman jailed for fictional unpublished...   \n",
       "...                                                  ...   \n",
       "20795  Rapper T.I.: Trump a ’Poster Child For White S...   \n",
       "20796  N.F.L. Playoffs: Schedule, Matchups and Odds -...   \n",
       "20797  Macy’s Is Said to Receive Takeover Approach by...   \n",
       "20798  NATO, Russia To Hold Parallel Exercises In Bal...   \n",
       "20799                          What Keeps the F-35 Alive   \n",
       "\n",
       "                                                    text  label  \n",
       "0      House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1      Ever get the feeling your life circles the rou...      0  \n",
       "2      Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3      Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4      Print \\nAn Iranian woman has been sentenced to...      1  \n",
       "...                                                  ...    ...  \n",
       "20795  Rapper T. I. unloaded on black celebrities who...      0  \n",
       "20796  When the Green Bay Packers lost to the Washing...      0  \n",
       "20797  The Macy’s of today grew from the union of sev...      0  \n",
       "20798  NATO, Russia To Hold Parallel Exercises In Bal...      1  \n",
       "20799    David Swanson is an author, activist, journa...      1  \n",
       "\n",
       "[20800 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['title', 'text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T08:32:25.412936Z",
     "start_time": "2020-06-29T08:32:25.392937Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[['id','text','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T08:32:26.502031Z",
     "start_time": "2020-06-29T08:32:26.492992Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.fillna('0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer for text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T08:32:49.561295Z",
     "start_time": "2020-06-29T08:32:37.184287Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                               text  label\n",
      "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...      1\n",
      "1   1  Ever get the feeling your life circles the rou...      0\n",
      "2   2  Why the Truth Might Get You Fired October 29, ...      1\n",
      "3   3  Videos 15 Civilians Killed In Single US Airstr...      1\n",
      "4   4  Print \\nAn Iranian woman has been sentenced to...      1\n",
      "['00', '000', '0000', '0001', '0002', '0002062', '000billion', '000c', '000ft', '000km']\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Print the head of df\n",
    "print(df.head())\n",
    "\n",
    "# Create a series to store the labels: y\n",
    "y = df.label\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], y, test_size = 0.33, random_state = 53)\n",
    "\n",
    "# Initialize a CountVectorizer object: count_vectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words= 'english')\n",
    "\n",
    "# Transform the training data using only the 'text' column values: count_train \n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using only the 'text' column values: count_test \n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "# Print the first 10 features of the count_vectorizer\n",
    "print(count_vectorizer.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TfidfVectorizer for text classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T08:45:45.600792Z",
     "start_time": "2020-06-29T08:45:23.216283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '0001', '0002', '0002062', '000billion', '000c', '000ft', '000km']\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df =0.7)\n",
    "\n",
    "# Transform the training data: tfidf_train \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data: tfidf_test \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Print the first 10 features\n",
    "print(tfidf_vectorizer.get_feature_names()[:10])\n",
    "\n",
    "# Print the first 5 vectors of the tfidf training data\n",
    "print(tfidf_train.A[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the vectors\n",
    "\n",
    "To get a better idea of how the vectors work, you'll investigate them by converting them into pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T08:49:01.876640Z",
     "start_time": "2020-06-29T08:48:41.520838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   00  000  0000  0001  0002  0002062  000billion  000c  000ft  000km  ...  \\\n",
      "0   0    0     0     0     0        0           0     0      0      0  ...   \n",
      "1   0    0     0     0     0        0           0     0      0      0  ...   \n",
      "2   0    0     0     0     0        0           0     0      0      0  ...   \n",
      "3   0    0     0     0     0        0           0     0      0      0  ...   \n",
      "4   0    0     0     0     0        0           0     0      0      0  ...   \n",
      "\n",
      "   鉴于当代挑战和威胁的全球性质  集体安全条约组织  集体安全条约组织与联合国专门机构  集体安全条约组织是多层面结构  \\\n",
      "0               0         0                 0               0   \n",
      "1               0         0                 0               0   \n",
      "2               0         0                 0               0   \n",
      "3               0         0                 0               0   \n",
      "4               0         0                 0               0   \n",
      "\n",
      "   集体安全条约组织正在积极促进帮助阿富汗进行冲突后重建以及消除来自该国的毒品威胁的国际努力  集体安全条约组织秘书长博尔久扎  集体提出创新办法  \\\n",
      "0                                             0                0         0   \n",
      "1                                             0                0         0   \n",
      "2                                             0                0         0   \n",
      "3                                             0                0         0   \n",
      "4                                             0                0         0   \n",
      "\n",
      "   非法贩运毒品以及确保国际信息安全  预防和解决冲突  ｓꮭ  \n",
      "0                 0        0   0  \n",
      "1                 0        0   0  \n",
      "2                 0        0   0  \n",
      "3                 0        0   0  \n",
      "4                 0        0   0  \n",
      "\n",
      "[5 rows x 144752 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create the CountVectorizer DataFrame: count_df\n",
    "count_df = pd.DataFrame( count_train.A, \n",
    "            columns=count_vectorizer.get_feature_names())\n",
    "\n",
    "# Create the TfidfVectorizer DataFrame: tfidf_df\n",
    "tfidf_df = pd.DataFrame(tfidf_train.A, \n",
    "            columns = tfidf_vectorizer.get_feature_names())\n",
    "\n",
    "# Print the head of count_df\n",
    "print(count_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T08:49:18.373209Z",
     "start_time": "2020-06-29T08:49:18.349207Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    00  000  0000  0001  0002  0002062  000billion  000c  000ft  000km  ...  \\\n",
      "0  0.0  0.0   0.0   0.0   0.0      0.0         0.0   0.0    0.0    0.0  ...   \n",
      "1  0.0  0.0   0.0   0.0   0.0      0.0         0.0   0.0    0.0    0.0  ...   \n",
      "2  0.0  0.0   0.0   0.0   0.0      0.0         0.0   0.0    0.0    0.0  ...   \n",
      "3  0.0  0.0   0.0   0.0   0.0      0.0         0.0   0.0    0.0    0.0  ...   \n",
      "4  0.0  0.0   0.0   0.0   0.0      0.0         0.0   0.0    0.0    0.0  ...   \n",
      "\n",
      "   鉴于当代挑战和威胁的全球性质  集体安全条约组织  集体安全条约组织与联合国专门机构  集体安全条约组织是多层面结构  \\\n",
      "0             0.0       0.0               0.0             0.0   \n",
      "1             0.0       0.0               0.0             0.0   \n",
      "2             0.0       0.0               0.0             0.0   \n",
      "3             0.0       0.0               0.0             0.0   \n",
      "4             0.0       0.0               0.0             0.0   \n",
      "\n",
      "   集体安全条约组织正在积极促进帮助阿富汗进行冲突后重建以及消除来自该国的毒品威胁的国际努力  集体安全条约组织秘书长博尔久扎  集体提出创新办法  \\\n",
      "0                                           0.0              0.0       0.0   \n",
      "1                                           0.0              0.0       0.0   \n",
      "2                                           0.0              0.0       0.0   \n",
      "3                                           0.0              0.0       0.0   \n",
      "4                                           0.0              0.0       0.0   \n",
      "\n",
      "   非法贩运毒品以及确保国际信息安全  预防和解决冲突   ｓꮭ  \n",
      "0               0.0      0.0  0.0  \n",
      "1               0.0      0.0  0.0  \n",
      "2               0.0      0.0  0.0  \n",
      "3               0.0      0.0  0.0  \n",
      "4               0.0      0.0  0.0  \n",
      "\n",
      "[5 rows x 144752 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the head of tfidf_df\n",
    "print(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T08:49:24.427304Z",
     "start_time": "2020-06-29T08:49:24.289307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Calculate the difference in columns: difference\n",
    "difference = set(tfidf_df.columns) - set(count_df.columns)\n",
    "print(difference)\n",
    "\n",
    "# Check whether the DataFrames are equal\n",
    "print(count_df.equals(tfidf_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and testing the \"fake news\" model with CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T09:02:11.988521Z",
     "start_time": "2020-06-29T09:02:11.979522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.value_counts of 1748     1\n",
       "1795     0\n",
       "7870     0\n",
       "11693    1\n",
       "11048    1\n",
       "        ..\n",
       "4596     1\n",
       "8854     0\n",
       "19645    1\n",
       "14075    0\n",
       "2933     1\n",
       "Name: label, Length: 13936, dtype: int64>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classifier \n",
    "- Naive Bayes Model\n",
    "\t- commonly used for testing NLP classification problems\n",
    "\t- basis in probability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T09:02:55.568583Z",
     "start_time": "2020-06-29T09:02:55.508587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8978729603729604\n",
      "\n",
      "[[3283  127]\n",
      " [ 574 2880]]\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(count_test)\n",
    "\n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred)\n",
    "print('')\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and testing the \"fake news\" model with TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T09:10:05.082008Z",
     "start_time": "2020-06-29T09:10:05.018022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8534382284382285\n",
      "[[3376   34]\n",
      " [ 972 2482]]\n"
     ]
    }
   ],
   "source": [
    "# Create a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(tfidf_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(tfidf_test)\n",
    "\n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving your model\n",
    "\n",
    "Your job in this exercise is to test a few different alpha levels using the Tfidf vectors to determine if there is a better performing combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T09:18:03.638281Z",
     "start_time": "2020-06-29T09:18:03.249773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:  0.0\n",
      "Score:  0.8774766899766899\n",
      "\n",
      "Alpha:  0.1\n",
      "Score:  0.9013694638694638\n",
      "\n",
      "Alpha:  0.2\n",
      "Score:  0.8945221445221445\n",
      "\n",
      "Alpha:  0.30000000000000004\n",
      "Score:  0.8876748251748252\n",
      "\n",
      "Alpha:  0.4\n",
      "Score:  0.8806818181818182\n",
      "\n",
      "Alpha:  0.5\n",
      "Score:  0.8754370629370629\n",
      "\n",
      "Alpha:  0.6000000000000001\n",
      "Score:  0.8703379953379954\n",
      "\n",
      "Alpha:  0.7000000000000001\n",
      "Score:  0.8656759906759907\n",
      "\n",
      "Alpha:  0.8\n",
      "Score:  0.8611596736596736\n",
      "\n",
      "Alpha:  0.9\n",
      "Score:  0.8581002331002331\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the list of alphas: alphas\n",
    "alphas = np.arange(0,1, 0.1)\n",
    "\n",
    "# Define train_and_predict()\n",
    "def train_and_predict(alpha):\n",
    "    # Instantiate the classifier: nb_classifier\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "    # Fit to the training data\n",
    "    nb_classifier.fit(tfidf_train, y_train)\n",
    "    # Predict the labels: pred\n",
    "    pred = nb_classifier.predict(tfidf_test)\n",
    "    # Compute accuracy: score\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    return score\n",
    "\n",
    "# Iterate over the alphas and print the corresponding score\n",
    "for alpha in alphas:\n",
    "    print('Alpha: ', alpha)\n",
    "    print('Score: ', train_and_predict(alpha))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting your model\n",
    "\n",
    "Now that you have built a \"fake news\" classifier, you'll investigate what it has learned. You can map the important vector weights back to actual words using some simple inspection techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T09:23:01.610330Z",
     "start_time": "2020-06-29T09:23:01.277694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [(-12.272119266891478, '0000'), (-12.272119266891478, '000c'), (-12.272119266891478, '000s'), (-12.272119266891478, '003'), (-12.272119266891478, '014'), (-12.272119266891478, '0200gmt'), (-12.272119266891478, '021'), (-12.272119266891478, '022'), (-12.272119266891478, '036'), (-12.272119266891478, '046'), (-12.272119266891478, '055'), (-12.272119266891478, '060'), (-12.272119266891478, '061'), (-12.272119266891478, '064'), (-12.272119266891478, '068'), (-12.272119266891478, '072'), (-12.272119266891478, '074'), (-12.272119266891478, '077'), (-12.272119266891478, '0800'), (-12.272119266891478, '085')]\n",
      "\n",
      "\n",
      "1 [(-7.968809440416186, 'government'), (-7.955071684537176, 'time'), (-7.928203647965548, 'state'), (-7.91901515859573, 'media'), (-7.905447278651641, 'president'), (-7.884950835742675, 'like'), (-7.884059282507659, 'war'), (-7.853272523785743, 'obama'), (-7.832332443544034, 'new'), (-7.795349623141636, 'world'), (-7.780378901871515, 'just'), (-7.762635293021732, 'said'), (-7.739270719704102, 'russia'), (-7.645326352892548, 'fbi'), (-7.502956340401195, 'election'), (-7.497405957504812, '2016'), (-7.487924515120291, 'people'), (-7.077918877541891, 'hillary'), (-6.849303327203932, 'trump'), (-6.7934848301207555, 'clinton')]\n"
     ]
    }
   ],
   "source": [
    "# Get the class labels: class_labels\n",
    "class_labels = nb_classifier.classes_\n",
    "\n",
    "# Extract the features: feature_names\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# Zip the feature names together with the coefficient array and sort by weights: feat_with_weights\n",
    "feat_with_weights = sorted(zip(nb_classifier.coef_[0], feature_names))\n",
    "\n",
    "# Print the first class label and the top 20 feat_with_weights entries\n",
    "print(class_labels[0], feat_with_weights[:20])\n",
    "\n",
    "print('')\n",
    "print('')\n",
    "# Print the second class label and the bottom 20 feat_with_weights entries\n",
    "print(class_labels[1], feat_with_weights[-20:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
