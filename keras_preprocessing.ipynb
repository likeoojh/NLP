{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T06:27:13.287023Z",
     "start_time": "2020-07-03T06:27:12.774518Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "news_train = fetch_20newsgroups(subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T06:28:28.823076Z",
     "start_time": "2020-07-03T06:28:26.286374Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T06:30:40.744776Z",
     "start_time": "2020-07-03T06:30:40.740105Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first instantiate the class and keep it on the variable tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T06:33:04.094222Z",
     "start_time": "2020-07-03T06:33:01.541814Z"
    }
   },
   "outputs": [],
   "source": [
    "# create and fit the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "# this update the tokenizer instance with the vacabulary and indexes\n",
    "tokenizer.fit_on_texts(news_train.data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the tokenizer dot texts to sequences method, and apply on the news_train dot data save the results in the x_train variable\n",
    "\n",
    "- we pad the sequences for them to have the same length using the pad_sequences function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T06:38:28.469967Z",
     "start_time": "2020-07-03T06:38:26.589167Z"
    }
   },
   "outputs": [],
   "source": [
    "# create the (x,y) variables\n",
    "# Transform the text into numerical indexes\n",
    "X_train = tokenizer.texts_to_sequences(news_train.data)\n",
    "X_train = pad_sequences(X_train, maxlen = 400)\n",
    "Y_train = to_categorical(news_train.target) # one-hot encoded matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T06:38:44.738426Z",
     "start_time": "2020-07-03T06:38:44.727871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 400)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change text for numerical ids and pad\n",
    "#X_novel = tokenizer.texts_to_sequences(news_novel.data)\n",
    "#X_novel = pad_sequences(X_novel, maxlen=400)\n",
    "\n",
    "# One-hot encode the labels\n",
    "#Y_novel = to_categorical(news_novel.target)\n",
    "\n",
    "# Load the model pre-trained weights\n",
    "#model.load_weights('classify_news_weights.h5')\n",
    "\n",
    "# Evaluate the model on the new dataset\n",
    "#loss, acc = model.evaluate(X_novel, Y_novel, batch_size=64)\n",
    "\n",
    "# Print the loss and accuracy obtained\n",
    "#print(\"Loss:\\t{0}\\nAccuracy:\\t{1}\".format(loss, acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
